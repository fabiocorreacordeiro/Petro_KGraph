{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b76b2f10",
   "metadata": {},
   "source": [
    "### Notebook para treinar modelo de Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b60982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senha: ········\n"
     ]
    }
   ],
   "source": [
    "# Configurando Proxy\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "chave  = os.getenv('USER')\n",
    "senha  = getpass('Senha: ')\n",
    "\n",
    "os.environ['HTTP_PROXY']  = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['HTTPS_PROXY'] = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['NO_PROXY']    = '127.0.0.1, localhost, petrobras.com.br, petrobras.biz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd1b6317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "# import glob\n",
    "\n",
    "print(tf.config.experimental.list_physical_devices('GPU'))\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb98f3d",
   "metadata": {},
   "source": [
    "### Carregando dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd958b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER_NAME_TO_SAVE = \"TESTE1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc637cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./../Lucas/df_bert_sentences_13_04.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0da3498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_e</th>\n",
       "      <th>sentence</th>\n",
       "      <th>Ent1</th>\n",
       "      <th>Ent2</th>\n",
       "      <th>has_relation</th>\n",
       "      <th>relation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>[E1] Membro Mucuri [/E1], [E2] Eocretáceo [/E2...</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>[E1] Membro Mucuri [/E1], Eocretáceo    [E2] B...</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>True</td>\n",
       "      <td>located_in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>[E2] Membro Mucuri [/E2], [E1] Eocretáceo [/E1...</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>UNIDADE_LITO</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Membro Mucuri, [E1] Eocretáceo [/E1]    [E2] B...</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>Ferreira 121 a Expressão de Reativações Pós-in...</td>\n",
       "      <td>UNIDADE_CRONO</td>\n",
       "      <td>BACIA</td>\n",
       "      <td>False</td>\n",
       "      <td>no_relation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index_e                                           sentence           Ent1  \\\n",
       "0        6  [E1] Membro Mucuri [/E1], [E2] Eocretáceo [/E2...   UNIDADE_LITO   \n",
       "1        6  [E1] Membro Mucuri [/E1], Eocretáceo    [E2] B...   UNIDADE_LITO   \n",
       "2        6  [E2] Membro Mucuri [/E2], [E1] Eocretáceo [/E1...  UNIDADE_CRONO   \n",
       "3        6  Membro Mucuri, [E1] Eocretáceo [/E1]    [E2] B...  UNIDADE_CRONO   \n",
       "4       36  Ferreira 121 a Expressão de Reativações Pós-in...  UNIDADE_CRONO   \n",
       "\n",
       "            Ent2  has_relation     relation  \n",
       "0  UNIDADE_CRONO         False  no_relation  \n",
       "1          BACIA          True   located_in  \n",
       "2   UNIDADE_LITO         False  no_relation  \n",
       "3          BACIA         False  no_relation  \n",
       "4          BACIA         False  no_relation  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3e9055f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_relation  2272\n",
      "df_no_relation  11632\n"
     ]
    }
   ],
   "source": [
    "df_no_relation = df[df[\"has_relation\"] == False]\n",
    "df_relation = df[df[\"has_relation\"] == True]\n",
    "\n",
    "print(\"df_relation \", len(df_relation))\n",
    "print(\"df_no_relation \", len(df_no_relation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c210b42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no_relation',\n",
       " 'located_in',\n",
       " 'temporal_relation',\n",
       " 'constituted_by',\n",
       " 'has_age',\n",
       " 'atravessa',\n",
       " 'interval_finishes',\n",
       " 'interval_in']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#relations\n",
    "\n",
    "relations = list(df[\"relation\"].unique())\n",
    "relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1840e500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num  no_relation 11632\n",
      "num  located_in 525\n",
      "num  temporal_relation 1239\n",
      "num  constituted_by 402\n",
      "num  has_age 75\n",
      "num  atravessa 29\n",
      "num  interval_finishes 1\n",
      "num  interval_in 1\n"
     ]
    }
   ],
   "source": [
    "for relation in relations:\n",
    "    print(\"num \", relation, len(df[df[\"relation\"] == relation]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69def017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relacoes que quero usar\n",
    "relations = [\n",
    " 'located_in',\n",
    " 'temporal_relation',\n",
    " 'constituted_by',\n",
    " 'has_age',\n",
    " 'atravessa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fcbcf72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation  located_in\n",
      "-- train  365\n",
      "-- val  103\n",
      "-- test  52\n",
      "relation  temporal_relation\n",
      "-- train  849\n",
      "-- val  242\n",
      "-- test  120\n",
      "relation  constituted_by\n",
      "-- train  281\n",
      "-- val  79\n",
      "-- test  39\n",
      "relation  has_age\n",
      "-- train  49\n",
      "-- val  13\n",
      "-- test  6\n",
      "relation  atravessa\n",
      "-- train  20\n",
      "-- val  5\n",
      "-- test  2\n"
     ]
    }
   ],
   "source": [
    "df_final_train = pd.DataFrame()\n",
    "df_final_val = pd.DataFrame()\n",
    "df_final_test = pd.DataFrame()\n",
    "\n",
    "# df relations separa 70 20 10\n",
    "for relation in relations:\n",
    "    #relation = relations[0]\n",
    "    df_filter  = df_relation[df_relation[\"relation\"] == relation]\n",
    "    total_len = len(df_filter)\n",
    "    df_filter.sample(frac=1, random_state=1) # mistura\n",
    "\n",
    "    qtd_train = round(total_len*0.7)\n",
    "    qtd_val = round(total_len*0.2)\n",
    "\n",
    "    df_train = df_filter.iloc[:qtd_train,:]\n",
    "    df_val = df_filter.iloc[qtd_train+1:qtd_train+qtd_val,:]\n",
    "    df_test = df_filter.iloc[qtd_train+qtd_val+1:,:]\n",
    "\n",
    "    df_final_train = pd.concat([df_final_train, df_train ])\n",
    "    df_final_val = pd.concat([df_final_val, df_val ])\n",
    "    df_final_test = pd.concat([df_final_test, df_test ])\n",
    "    \n",
    "    print(\"relation \", relation)\n",
    "    print(\"-- train \", len(df_train))\n",
    "    print(\"-- val \", len(df_val))\n",
    "    print(\"-- test \", len(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b2bb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df_final_train = len(df_final_train)\n",
    "len_df_final_val = len(df_final_val)\n",
    "len_df_final_test = len(df_final_test)\n",
    "\n",
    "# Add info sem relacoes\n",
    "\n",
    "df_train_no_rel = df_no_relation.iloc[:len_df_final_train,:]\n",
    "df_val_no_rel = df_no_relation.iloc[len_df_final_train+1:len_df_final_train+len_df_final_val,:]\n",
    "df_test_no_rel = df_no_relation.iloc[len_df_final_train+len_df_final_val+1:len_df_final_train+len_df_final_val+len_df_final_test,:]\n",
    "\n",
    "df_final_train = pd.concat([df_final_train, df_train_no_rel ])\n",
    "df_final_val = pd.concat([df_final_val, df_val_no_rel ])\n",
    "df_final_test = pd.concat([df_final_test, df_test_no_rel ])\n",
    "\n",
    "# mistura\n",
    "\n",
    "df_final_train = df_final_train.sample(frac=1, random_state=1)\n",
    "df_final_val = df_final_val.sample(frac=1, random_state=1)\n",
    "df_final_test = df_final_test.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab74d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_y_from_df(df_final):\n",
    "    x,y = [], []\n",
    "    for index, row in df_final.iterrows():        \n",
    "        x.append([row[\"sentence\"]])\n",
    "        if row[\"has_relation\"]:\n",
    "            y.append(1)\n",
    "        else:\n",
    "            y.append(0)\n",
    "    return np.asarray(x), np.asarray(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d019dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforma df_final_train  df_final_val  df_final_test  em arrays x e y\n",
    "\n",
    "x_train, y_train = get_x_y_from_df(df_final_train)\n",
    "x_val, y_val = get_x_y_from_df(df_final_val)\n",
    "x_test, y_test = get_x_y_from_df(df_final_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c67619c6",
   "metadata": {},
   "source": [
    "### Treinando o modelo de Relation Extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4da3b4cf",
   "metadata": {},
   "source": [
    "Escolhendo modelo para carregar do TensorFlow HUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dfc87db5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "bert_model_name = 'small_bert/bert_en_uncased_L-2_H-128_A-2' \n",
    "\n",
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5def0969",
   "metadata": {},
   "source": [
    "Construindo modelo que recebe as sentenças com as devidas marcações indicando as entidades e que tem como output 0 caso não exista relação entre as duas entidades ou 1 caso exista (classificação binaria). Podemos alterar o output para que a saída seja um vetor de 0 e 1 indicando a existência ou não de cada tipo de relação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e4c8d49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    #Texto de input\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    # Camada de preprocessamento\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    # Camada BERT encode\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    # Selecionando apenas o 'pooled_output' do BERT encode \n",
    "    net = outputs['pooled_output']\n",
    "    # Camada de dropout\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    # Camada densa de saída, com a mesma dimensão do vetor OWL2Vec\n",
    "    net = tf.keras.layers.Dense(64, activation='relu', name='last_layer')(net)\n",
    "    net = tf.keras.layers.Dense(1, activation=None, name='output')(net)\n",
    "    return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1896c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graphs(history, model_type_name, FOLDER_NAME_TO_SAVE):\n",
    "    plt.clf()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(f\"{FOLDER_NAME_TO_SAVE}/{model_type_name}/{model_type_name}_acc.png\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    plt.clf()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.savefig(f\"{FOLDER_NAME_TO_SAVE}/{model_type_name}/{model_type_name}_loss.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3c0f70cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de texto alimentado como input do modelo e outuput no formato do vetor OWL2Vec\n",
    "# Como ainda não foi treinado, o vetor ainda não faz sentido.\n",
    "\n",
    "# text_test = np.array(['blablabla blablabla blablabla [E1] Nome da entidade [/E1] blablabla blablabla [E2] Nome da entidade [/E2] blabla.', \n",
    "#                      'blablabla blablabla [E2] Nome da entidade [/E2] blablabla blablabla [E1] Nome da entidade [/E1] blabla.'])\n",
    "#model(tf.constant(text_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16555dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_names = list(map_name_to_handle.keys())\n",
    "\n",
    "for bert_model_name in bert_model_names:\n",
    "    model_type_name = bert_model_name.replace(\"/\",\"_\")\n",
    "    \n",
    "    if not os.path.exists(f\"{FOLDER_NAME_TO_SAVE}/{model_type_name}\"):\n",
    "        os.makedirs(f\"{FOLDER_NAME_TO_SAVE}/{model_type_name}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "    tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "    print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "    print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')\n",
    "    \n",
    "    model = build_model(tfhub_handle_encoder, tfhub_handle_preprocess)\n",
    "    \n",
    "    es_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=20, restore_best_weights=True)\n",
    "    checkpointer = tf.keras.callbacks.ModelCheckpoint(f'{FOLDER_NAME_TO_SAVE}/{model_type_name}/model_{model_type_name}.h5', monitor='val_loss', verbose=2, save_best_only=True, save_weights_only=True)\n",
    "    \n",
    "    # Compilando o modelo\n",
    "    model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.RMSprop(1e-4), #0.0001\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    history = model.fit(x=x_train, \n",
    "                    y=y_train,\n",
    "                    batch_size=32,\n",
    "                    epochs=500,\n",
    "                    #validation_split=0.2,\n",
    "                    validation_data=(x_val,y_val),\n",
    "                    callbacks=[checkpointer, es_callback])\n",
    "    \n",
    "    create_graphs(history, model_type_name, FOLDER_NAME_TO_SAVE)\n",
    "\n",
    "    #load weights\n",
    "    model_eval = build_model(tfhub_handle_encoder, tfhub_handle_preprocess)\n",
    "    model_eval.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.RMSprop(1e-4), #0.0001\n",
    "              metrics=['accuracy'])\n",
    "    model_eval.load_weights(f'{FOLDER_NAME_TO_SAVE}/{model_type_name}/model_{model_type_name}.h5')\n",
    "    \n",
    "    test_loss, test_acc = model_eval.evaluate(x=x_test, y=y_test)\n",
    "    \n",
    "    with open(f'{FOLDER_NAME_TO_SAVE}/{model_type_name}/{model_type_name}.txt', 'w') as f:\n",
    "        f.write(f'Test Loss: {test_loss}\\n')\n",
    "        f.write(f'Test Accuracy: {test_acc}\\n')\n",
    "\n",
    "    print('Test Loss:', test_loss)\n",
    "    print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152623c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfc6408",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
