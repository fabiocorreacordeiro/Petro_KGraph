{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde9826e-fb7a-4e88-9086-2157d9949fac",
   "metadata": {},
   "source": [
    "### Notebook para realizar a predição do Entity Linking nos documentos novos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2dc2bf9-c947-45fe-af0a-74c7dd7f3dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Senha:  ··········\n"
     ]
    }
   ],
   "source": [
    "# Configurando Proxy\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "chave  = os.getenv('USER')\n",
    "senha  = getpass('Senha: ')\n",
    "\n",
    "os.environ['HTTP_PROXY']  = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['HTTPS_PROXY'] = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['NO_PROXY']    = '127.0.0.1, localhost, petrobras.com.br, petrobras.biz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80762a08-0a91-4b51-9805-2f5b9160494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFBertModel\n",
    "import gensim\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bd4ed7-83ae-43fb-99cb-f6ad9b3450ff",
   "metadata": {},
   "source": [
    "### Carregando modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d50621-c3e9-4b46-a2b2-dd184c0f4f67",
   "metadata": {},
   "source": [
    "Carregando modelo base já treinado - Sentence2PetroOntoVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24abe046-f008-4d91-a7fc-24e256849de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.load_model(\"../Instances clustering/Sentence2PetroOntoVec_clustering\",\n",
    "                                      compile=False, \n",
    "                                      custom_objects={\"TFBertModel\": TFBertModel})\n",
    "\n",
    "#base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848cb786-a350-442f-9e01-18cd5bc2def4",
   "metadata": {},
   "source": [
    "Carregando Tokenizador usado no treinamento do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f60fc479-bbf6-40bd-ba10-e4ebb79d2f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir o modelo pretreinado a ser usado\n",
    "\n",
    "# \"neuralmind/bert-large-portuguese-cased\"\n",
    "# (Bert-tiny) 'google/bert_uncased_L-2_H-128_A-2' \n",
    "# 'bert-base-multilingual-cased'\n",
    "\n",
    "model_checkpoint = \"neuralmind/bert-large-portuguese-cased\"  \n",
    "\n",
    "# Tamano máximo da sentença\n",
    "max_length = 512 #128 #512\n",
    "\n",
    "# Carregar o tokenizador\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c36164f-791c-489c-8d3d-f6cc159f49ea",
   "metadata": {},
   "source": [
    "Carregando modelo PetroOntoVec (OWL2Vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f72f2cf-f3d5-4ca8-be7c-63896b72ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando Modelo OWL2Vec - \n",
    "PetroOntoVec = gensim.models.Word2Vec.load(\"../../Embeddings/PetroOntoVec/Petrovec-OeG_NP2/outputontology.embeddings\")\n",
    "ontology_uri = 'http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc7d797-aaef-46fa-81a5-1c6f04e4d21d",
   "metadata": {},
   "source": [
    "Funções auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57cbeabe-4a86-4d05-9763-390e77a1d077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# função apra separar anotações iniciais das sentenças propriamente ditas\n",
    "\n",
    "def split_pre_sent(dataset):\n",
    "    new_dataset_pre = []\n",
    "    new_dataset_sentence = []\n",
    "    \n",
    "    for sent in dataset:\n",
    "        par_sent = sent.split('|')\n",
    "        new_dataset_pre.append(par_sent[0])\n",
    "        new_dataset_sentence.append(par_sent[1])\n",
    "\n",
    "    return (new_dataset_pre, new_dataset_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed316e0f-b49b-45a0-a969-46d737c81b3b",
   "metadata": {},
   "source": [
    "Função para receber a sentença e predizer o vetor no espaçõ vetorial PetroOntoVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b477c63-0dbe-4917-8c1c-b25831f4d118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_PetroOntoVec(text_pre, text_sent):\n",
    "    \n",
    "    X = dict(tokenizer(text_pre, text_sent,\n",
    "                       truncation=True,\n",
    "                       is_split_into_words=False,\n",
    "                       padding=\"max_length\",\n",
    "                       max_length=max_length))\n",
    "\n",
    "    X_ids = tf.convert_to_tensor(X['input_ids'])\n",
    "    X_mask = tf.convert_to_tensor(X['attention_mask'])\n",
    "\n",
    "    embedding = base_model.predict([X_ids, X_mask])\n",
    "    \n",
    "    return (embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e56a47-db3a-49df-9d05-9201822333ab",
   "metadata": {},
   "source": [
    "Função para receber o embedding e achar a URI mais próxima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e13b0c8-33da-43f0-bd5d-c3a553ecd5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def URI_sim(embedding):\n",
    "    \n",
    "    alpha = 0.05\n",
    "    sim = 1 - alpha\n",
    "    most_similar = PetroOntoVec.wv.most_similar(embedding, topn=100)\n",
    "    \n",
    "    for m in most_similar:\n",
    "        # Só fazer pridicção se similaridade for maior que \"SIM\"\n",
    "        if m[1] > sim:\n",
    "            # Verificar se o vetor é de uma URI\n",
    "            if m[0][:len(ontology_uri)] == ontology_uri:\n",
    "                \n",
    "                return (m[0][len(ontology_uri):])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3328e846-aa11-42a2-8c88-71deca5f6ea0",
   "metadata": {},
   "source": [
    "### Predizendo as URI e embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83b067e2-6627-4754-8734-9efbc94d98a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petroner-uri-teste.json\n"
     ]
    }
   ],
   "source": [
    "# path_json = \"../../Corpora/Predicao/Prediction_json/\"  # Documentos novos\n",
    "path_json = \"../../Corpora/Predicao - avaliação/Prediction_json/\"  # PetroNER-teste para avaliação do pipeline\n",
    "\n",
    "# Lista com as URI Linkadas\n",
    "linked_URIs = []\n",
    "\n",
    "# Iterando por cada arquivo\n",
    "for file in os.listdir(path_json):\n",
    "    filename = os.fsdecode(file)\n",
    "    if file.endswith(\".json\"):\n",
    "        print(filename)\n",
    "        \n",
    "        with open(path_json + filename, 'r') as f:\n",
    "            pred_dic = json.load(f)\n",
    "        \n",
    "        sentence_key = pred_dic.keys()\n",
    "        \n",
    "        # Iterando por cada sentença\n",
    "        for key in sentence_key:\n",
    "            Sentencas_processadas = pred_dic[key]['NER']['Sent_processadas']\n",
    "            \n",
    "            if Sentencas_processadas != []:\n",
    "                \n",
    "                graf = []\n",
    "                emb = []\n",
    "            \n",
    "                for Sent_process in Sentencas_processadas:\n",
    "\n",
    "                    # Separando a parte inicial (classe e intância do corpo da sentença) \n",
    "                    Sent_process_pre, Sent_process_sent = split_pre_sent([Sent_process])\n",
    "\n",
    "                    # Inferindo o vetor e identificando a URI mais próxima\n",
    "                    embedding = pred_PetroOntoVec(Sent_process_pre, Sent_process_sent)\n",
    "                    URI = URI_sim(embedding)\n",
    "                    if URI != None:\n",
    "                        graf.append(URI)\n",
    "                        linked_URIs.append(URI)\n",
    "                        emb.append(None)\n",
    "\n",
    "                    else:\n",
    "                        graf.append(None)\n",
    "                        emb.append(embedding[0].tolist())\n",
    "\n",
    "                        \n",
    "                pred_dic[key]['NER']['Grafo'] = graf\n",
    "                pred_dic[key]['NER']['Embedding'] = emb\n",
    "\n",
    "        #Salvando o arquivo JSON\n",
    "        with open(path_json + filename, 'w+') as f:\n",
    "            json.dump(pred_dic, f)\n",
    "\n",
    "            \n",
    "# path_entities = \"../../Corpora/Predicao/Prediction_graph/\"            # Documentos novos\n",
    "path_entities = \"../../Corpora/Predicao - avaliação/Prediction_graph/\"  # PetroNER-teste para avaliação do pipeline\n",
    "filename_entities = \"Linked_entities\"\n",
    "\n",
    "#Salvando o arquivo com as entidades (URIs) linkadas\n",
    "with open(path_entities + filename_entities, 'w+') as f:\n",
    "    json.dump(list(set(linked_URIs)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883dbc98-a4b1-452c-aea3-5e80b497eb35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
