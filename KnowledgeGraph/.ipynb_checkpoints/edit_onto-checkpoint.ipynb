{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import unicodedata\n",
    "from owlready2 import *\n",
    "from getpass import getpass\n",
    "from IPython.display import clear_output\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"file://OntoGeoLogicaEntidadesNomeadasPython.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Senha:  ··········\n"
     ]
    }
   ],
   "source": [
    "chave  = os.getenv('BG40')\n",
    "senha  = getpass('Senha: ')\n",
    "\n",
    "os.environ['HTTP_PROXY']  = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['HTTPS_PROXY'] = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['NO_PROXY']    = '127.0.0.1, localhost, petrobras.com.br, petrobras.biz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_ontology(\"http://www.semanticweb.org/bg40/ontologies/2022/5/untitled-ontology-2#\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ontology_iri = str(onto.field.iri).split('#')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert list of basins as individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates instances for the BASIN entity. Each instance is registered under a URI with an unique code (BASE_CD_BACIA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_bacias = 'resources/bacia/bacias.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lista_bacias, 'r') as f:\n",
    "    individuos = json.load(f)\n",
    "\n",
    "for individuo in individuos:\n",
    "    new_ind=onto.basin('BASE_CD_BACIA_'+str(individuo).zfill(3))\n",
    "    for sinonimo in individuos[individuo]:\n",
    "        new_ind.label.append(sinonimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert list of fields as individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates instances for the FIELD entity. Each instance is registered under a URI with an unique code (CAMP_CD_CAMPO).\n",
    "\n",
    "Each fields is also related to the basin in which it is located (**field** *located_in* **basin**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_campos = 'resources/campo/campos.json'\n",
    "relacoes_campo_bacia = 'resources/relacoes/campo_bacia.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lista_campos, 'r') as f:\n",
    "    individuos = json.load(f)\n",
    "\n",
    "#with open(relacoes_campo_bacia, 'r') as f:\n",
    "#    relacoes = json.load(f)\n",
    "    \n",
    "for individuo in individuos:\n",
    "    new_ind=onto.field('CAMP_CD_CAMPO_'+str(individuo).zfill(4))\n",
    "    for sinonimo in individuos[individuo]:\n",
    "        new_ind.label.append(sinonimo)\n",
    "\n",
    "#As relações serão inseridas de forma separada\n",
    "#    for bacia in onto.search(iri = \"*BASE_CD_BACIA_*\"):\n",
    "#        if relacoes[individuo] in bacia.label:\n",
    "#            new_ind.located_in.append(bacia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert list of lithostratigraphic units as individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Creates instances for the LITHOSTRATIGRAPHIC_UNIT entity. Each instance is registered under a sequential numeric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_unidades_litoestratigraficas = 'resources/litoestratigrafia/unidades_litoestratigraficas.json'\n",
    "with open(lista_unidades_litoestratigraficas, 'r') as f:\n",
    "    individuos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for formacao in individuos['formation'].keys():\n",
    "    new_formation=onto.formation(formacao)\n",
    "    for nome_unidade in individuos['formation'][formacao]:\n",
    "        new_formation.label.append(nome_unidade)\n",
    "\n",
    "for grupo in individuos['group'].keys():\n",
    "    new_group=onto.group(grupo)\n",
    "    for nome_unidade in individuos['group'][grupo]:\n",
    "        new_group.label.append(nome_unidade)\n",
    "        \n",
    "for membro in individuos['member'].keys():\n",
    "    new_member=onto.member(membro)\n",
    "    for nome_unidade in individuos['member'][membro]:\n",
    "        new_member.label.append(nome_unidade)  \n",
    "\n",
    "new_lito=onto.lithostratigraphic_unit('SD_000')\n",
    "new_lito.label.append('Embasamento')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert geological structure instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates instances for the GEOLOGICAL STRUCTURE entity. Each instance is registered under a URI with an unique numeric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_estruturas = 'resources/estrutura_textura_porosidade/estrutura.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lista_estruturas, 'r') as f:\n",
    "    individuos = json.load(f)\n",
    "\n",
    "for individuo in individuos:\n",
    "    new_ind=onto.geological_structure('TEFR_CD_TIPO_EST_FISICA_ROCHA_'+str(individuo).zfill(3))\n",
    "    new_ind.label.append(individuos[individuo])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Insert texture instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates instances for the TEXTURE entity. Each instance is registered under a URI with an unique numeric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_texturas = 'resources/estrutura_textura_porosidade/textura.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lista_texturas, 'r') as f:\n",
    "    individuos = json.load(f)\n",
    "\n",
    "for individuo in individuos:\n",
    "    #new_ind=onto.textura('TIPH_CD_TIPO_POROSIDADE_ROCHA_'+str(individuo).zfill(3))  #AVALIAR NOVA NOMENCLATURA\n",
    "    new_ind=onto.textura('textura_'+str(individuo).zfill(3))\n",
    "    new_ind.label.append(individuos[individuo]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert porosity types instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates instances for the POROSITY entity. Each instance is registered under a URI with an unique numeric code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_porosidades = 'resources/estrutura_textura_porosidade/porosidade.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(lista_porosidades, 'r') as f:\n",
    "    individuos = json.load(f)\n",
    "\n",
    "for individuo in individuos:\n",
    "    #new_ind=onto.tipo_de_porosidade('TIPH_CD_TIPO_POROSIDADE_ROCHA'+str(individuo).zfill(3))  #PROPOSTA PARA ADEQUAR A PADRAO BDIEP\n",
    "    new_ind=onto.tipo_de_porosidade('porosidade_'+str(individuo).zfill(2))\n",
    "    new_ind.label.append(individuos[individuo]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Insert list of chronostratigraphic units as individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Creates instances for the CHRONOSTRATIGRAPHIC_UNIT entity. Each instance is registered under a URI that represents the instance name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_unidades_cronoestratigraficas = 'resources/cronoestratigrafia/unidades_cronoestratigraficas.json'\n",
    "with open(lista_unidades_cronoestratigraficas, 'r') as f:\n",
    "    individuos = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tipo_unidade_crono in individuos.keys():\n",
    "    #print(onto.search(iri = '*'+key))\n",
    "    for unidade_crono in individuos[tipo_unidade_crono].keys():\n",
    "        new_ind = onto.search(iri = ontology_iri+'#'+tipo_unidade_crono)[0](unidade_crono)\n",
    "        for nome_unidade in individuos[tipo_unidade_crono][unidade_crono]:\n",
    "            new_ind.label.append(nome_unidade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1642"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(onto.individuals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Insert list of wells as individuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _semhifen(name):\n",
    "    # DERIVANDO TERMO SEM OS HÍFENS \n",
    "    # EX. 3-RJS-739  => 3RJS739\n",
    "    # EX. 7-CRT-17HP-RJS => 7CRT17HPRJS\n",
    "    return(name.replace(\"-\",\"\"))\n",
    "\n",
    "def _semhifen_semuf(name):\n",
    "    # DERIVANDO TERMO SEM OS HÍFENS e sem o identificador de UF ao final  \n",
    "    # EX. 7-CRT-17HP-RJS => 7CRT17HP\n",
    "    return(re.sub(\"-[A-Z]{0,3}$\", '', name).replace(\"-\",\"\"))\n",
    "\n",
    "def _seminicio(name):\n",
    "    # EX. 7-CRT-17HP-RJS => CRT-17HP-RJS\n",
    "    return(re.sub(\"^[0-9]-\", '', name))\n",
    "\n",
    "def _semfim(name):\n",
    "    # EX. 7-CRT-17HP-RJS => 7-CRT-17HP\n",
    "    return(re.sub(\"-[A-Z]{0,3}$\", '', name))\n",
    "\n",
    "def _semtipo(name):\n",
    "    # retira indicação de tipo -> D H P A B C\n",
    "    # EX. 7-CRT-17HP-RJS => 7-CRT-17-RJS\n",
    "    return(re.sub(\"(?<=[0-9])[A-Z]{0,3}-\", '-', name))\n",
    "\n",
    "def _versaocurta(name):\n",
    "    # CRIAR ALTERNATIVA AO POCO_NM_COMPLETO COM NOME CURTO MUITO USUAL EM DOCUMENTOS\n",
    "    # EX. 8-LL-108D-RJS  => LL-108D\n",
    "    # EX. 3-RJS-739  => RJS-739\n",
    "    # EX. 3-RJS-739A => RJS-739A\n",
    "    #^ => identifica\tinício da linha \tmodelo = \"^abc\" \tMatch com = \"abcde\" \tassocia texto que inicia com a sequência \"abc\", embora não \"yabc\".\n",
    "    #$ => identifica\tfim da linha \tmodelo = \"abc$\" \tMatch com = \"yzabc\" \tassocia texto que termina com a sequência \"abc\", embora não \"abcde\". \n",
    "    return(re.sub(\"((^[0-9]-)|(-[A-Z]{0,3}$))\", '', name))\n",
    "    \n",
    "def _well_names(index, row):\n",
    "    wells = []\n",
    "    \n",
    "    SG_PRFX_POCO = row['DMPO_SG_PRFX_POCO']\n",
    "    wells.append(SG_PRFX_POCO)\n",
    "    wells.append(_semhifen(SG_PRFX_POCO))\n",
    "    wells.append(_semhifen_semuf(SG_PRFX_POCO))\n",
    "    wells.append(_seminicio(SG_PRFX_POCO))\n",
    "    wells.append(_semfim(SG_PRFX_POCO))\n",
    "    wells.append(_semtipo(SG_PRFX_POCO))\n",
    "    wells.append(_versaocurta(SG_PRFX_POCO))\n",
    "    \n",
    "    if row['DMPO_NM_CMPT_POCO'] != '':\n",
    "        NM_CMPT_POCO = row['DMPO_NM_CMPT_POCO']\n",
    "        wells.append(NM_CMPT_POCO)\n",
    "        wells.append(_semhifen(NM_CMPT_POCO))\n",
    "        wells.append(_semhifen_semuf(NM_CMPT_POCO))\n",
    "        wells.append(_seminicio(NM_CMPT_POCO))\n",
    "        wells.append(_semfim(NM_CMPT_POCO))\n",
    "        wells.append(_semtipo(NM_CMPT_POCO))\n",
    "        wells.append(_versaocurta(NM_CMPT_POCO))\n",
    "    \n",
    "    if row['DMPO_SG_PRFX_POCO_ANP'] != '':\n",
    "        SG_PRFX_POCO_ANP = row['DMPO_SG_PRFX_POCO_ANP']\n",
    "        wells.append(SG_PRFX_POCO_ANP)\n",
    "        wells.append(_semhifen(SG_PRFX_POCO_ANP))\n",
    "        wells.append(_semhifen_semuf(SG_PRFX_POCO_ANP))\n",
    "        wells.append(_seminicio(SG_PRFX_POCO_ANP))\n",
    "        wells.append(_semfim(SG_PRFX_POCO_ANP))\n",
    "        wells.append(_semtipo(SG_PRFX_POCO_ANP))\n",
    "        wells.append(_versaocurta(SG_PRFX_POCO_ANP))\n",
    "\n",
    "    if row['DMPO_SG_PREF_POCO_DEPEX'] != '':\n",
    "        # DERIVANDO TERMO SEM OS ESPAÇOS \n",
    "        # EX. 1EDA 0001 BA  => 1EDA0001BA\n",
    "        # EX. 1EBAN0001 SE  => 1EBAN0001SE\n",
    "        SG_PREF_POCO_DEPEX_SEMESPACO = row['DMPO_SG_PREF_POCO_DEPEX'].replace(\" \",\"\")\n",
    "        wells.append(SG_PREF_POCO_DEPEX_SEMESPACO)\n",
    "    \n",
    "        # DERIVANDO TERMO SEM OS ZEROS A ESQUERDA\n",
    "        # EX. 1EBAN0001SE  => 1EBAN1SE\n",
    "        # O techo (?<=[A-Z]) -> verifica se tem letra antes mas não considera na substituição, é chamado de asserção retroativa positiva\n",
    "        wells.append(re.sub(\"(?<=[A-Z])0{1,3}\", '', SG_PREF_POCO_DEPEX_SEMESPACO))\n",
    "\n",
    "        # DERIVANDO TERMO SEM OS ESPAÇOS ENTRE OS IDENTIFICADORES PARA HOMOGENEIZAR COM OUTRAS FONTES\n",
    "        # EX. 1EDA 0001 BA  => 1-EDA-0001-BA\n",
    "        # EX. 1EBAN0001 SE  => 1-EBAN-0001-SE\n",
    "        SG_PREF_POCO_DEPEX_COMHIFEN = re.sub(\"\\s{1,5}\", '-', row['DMPO_SG_PREF_POCO_DEPEX']) # SUBSTITUI ESPAÇOS\n",
    "        SG_PREF_POCO_DEPEX_COMHIFEN = re.sub(\"(?<=[A-Z])0\", '-0', SG_PREF_POCO_DEPEX_COMHIFEN)\n",
    "        SG_PREF_POCO_DEPEX_COMHIFEN = re.sub(\"(?<=[A-Z])00\", '-00', SG_PREF_POCO_DEPEX_COMHIFEN)\n",
    "        SG_PREF_POCO_DEPEX_COMHIFEN = re.sub(\"(?<=[A-Z])000\", '-000', SG_PREF_POCO_DEPEX_COMHIFEN)\n",
    "        wells.append(SG_PREF_POCO_DEPEX_COMHIFEN)\n",
    "    \n",
    "        # DERIVANDO TERMO SEM OS ZEROS A ESQUERDA E COM HÍFEN INICIAL NA SEGUNDA POSIÇÃO\n",
    "        # EX. 7CB-0017D-SES  => 7-CB-0017D-SES\n",
    "        s = SG_PREF_POCO_DEPEX_COMHIFEN\n",
    "        s = s[:1] + \"-\" +  s[1:]\n",
    "        wells.append(s)\n",
    "    \n",
    "        # DERIVANDO TERMO SEM OS ZEROS A ESQUERDA\n",
    "        # EX. 7CB-0017D-SES  => 7CB-17D-SES\n",
    "        # como existem dados ruins na base onde não existe o hífen para referenciar, tenho que tratar\n",
    "        SG_PREF_POCO_DEPEX_COMHIFEN_SEMZERONAESQUERDA = re.sub(\"(?<=[A-Z]|-)0{1,3}\", '', SG_PREF_POCO_DEPEX_COMHIFEN)\n",
    "        wells.append(SG_PREF_POCO_DEPEX_COMHIFEN_SEMZERONAESQUERDA)\n",
    "\n",
    "        # DERIVANDO TERMO SEM OS ZEROS A ESQUERDA E COM HÍFEN INICIAL NA SEGUNDA POSIÇÃO\n",
    "        # EX. 7CB-17D-SES  => 7-CB-17D-SES\n",
    "        s = SG_PREF_POCO_DEPEX_COMHIFEN_SEMZERONAESQUERDA\n",
    "        s = s[:1] + \"-\" +  s[1:]\n",
    "        wells.append(s)\n",
    "\n",
    "    return(set(wells))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _well_type(row):\n",
    "    wellTypeMap = {onto.well: ['NÃO ATRIBUÍDO'],\n",
    "                   onto.special_well: ['ESPECIAL'],\n",
    "                   onto.explotatory_well: ['INJECAO', 'PRODUCAO'],\n",
    "                   onto.adjacent_well: ['PIONEIRO ADJACENTE'],\n",
    "                   onto.appraisal_well: ['EXTENSAO'],\n",
    "                   onto.deeper_prospect_well: ['JAZIDA MAIS PROFUNDA'],\n",
    "                   onto.shallower_prospect_well: ['JAZIDA MAIS RASA'],\n",
    "                   onto.stratigraphic_well: ['ESTRATIGRAFICO'],\n",
    "                   onto.wildcat_well: ['PIONEIRO']\n",
    "                  }\n",
    "    for key, names in wellTypeMap.items():\n",
    "        if row['DMPO_NM_CLSS_POCO'] in names:\n",
    "            new_well = key('POCO_CD_POCO_'+str(row['DMPO_CD_POCO']).zfill(6))\n",
    "    return new_well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _well_quality(row):\n",
    "    well_quality = -1\n",
    "    wellQualityMap = {onto.abandonned_well: ['ABANDONADO POR ACIDENTE MECANICO',\n",
    "                                             'ABANDONADO POR BLOW-OUT',\n",
    "                                             'ABANDONADO POR IMPOSSIBILIDADE DE AVALIACAO',\n",
    "                                             'ABANDONADO POR OBJETIVO FORA DE PREVISAO',\n",
    "                                             'ABANDONADO POR OBJETIVO/ALVO NAO ATINGIDO',\n",
    "                                             'ABANDONADO POR OUTRAS RAZOES',\n",
    "                                             'ABANDONADO POR PERDA DE CIRCULACAO'\n",
    "                                            ] ,\n",
    "                      onto.commercial_well: ['PRODUTOR COMERCIAL DE GAS',\n",
    "                                             'PRODUTOR COMERCIAL DE GAS E CONDENSADO',\n",
    "                                             'PRODUTOR COMERCIAL DE OLEO',\n",
    "                                             'PRODUTOR COMERCIAL DE OLEO E GAS',\n",
    "                                             'PRODUTOR COMERCIAL DE OLEO, GAS E CONDENSADO'\n",
    "                                            ],\n",
    "                      onto.discovery_well: ['DESCOBRIDOR DE CAMPO COM GAS ',\n",
    "                                            'DESCOBRIDOR DE CAMPO COM GAS E CONDENSADO ',\n",
    "                                            'DESCOBRIDOR DE CAMPO COM OLEO ',\n",
    "                                            'DESCOBRIDOR DE CAMPO COM OLEO E GAS ',\n",
    "                                            'DESCOBRIDOR DE CAMPO COM OLEO, GAS E CONDENSADO',\n",
    "                                            'DESCOBRIDOR DE NOVA JAZIDA COM GAS',\n",
    "                                            'DESCOBRIDOR DE NOVA JAZIDA COM GAS E CONDENSADO',\n",
    "                                            'DESCOBRIDOR DE NOVA JAZIDA COM OLEO',\n",
    "                                            'DESCOBRIDOR DE NOVA JAZIDA COM OLEO E GAS',\n",
    "                                            'DESCOBRIDOR DE NOVA JAZIDA COM OLEO, GAS E CONDENSADO'\n",
    "                                           ],\n",
    "                      onto.dry_hole_without_traces_of_hydrocarbon: ['SECO SEM INDICIOS DE PETROLEO'\n",
    "                                                                   ],\n",
    "                      onto.dry_hole_with_traces_of_hydrocarbon: ['SECO COM INDICIOS DE GAS',\n",
    "                                                                 'SECO COM INDICIOS DE GAS E CONDENSADO',\n",
    "                                                                 'SECO COM INDICIOS DE OLEO',\n",
    "                                                                 'SECO COM INDICIOS DE OLEO E GAS',\n",
    "                                                                 'SECO COM INDICIOS DE OLEO, GAS E CONDENSADO'\n",
    "                                                                ],\n",
    "                      onto.well_with_hydrocarbon:['PORTADOR DE GAS',\n",
    "                                                  'PORTADOR DE GAS E CONDENSADO',\n",
    "                                                  'PORTADOR DE OLEO',\n",
    "                                                  'PORTADOR DE OLEO E GAS',\n",
    "                                                  'PORTADOR DE OLEO, GAS E CONDENSADO'\n",
    "                                                 ],\n",
    "                      onto.subcommercial_well: ['PRODUTOR SUBCOMERCIAL DE GAS ',\n",
    "                                                'PRODUTOR SUBCOMERCIAL DE GAS E CONDENSADO ',\n",
    "                                                'PRODUTOR SUBCOMERCIAL DE OLEO',\n",
    "                                                'PRODUTOR SUBCOMERCIAL DE OLEO E GAS ',\n",
    "                                                'PRODUTOR SUBCOMERCIAL DE OLEO,GAS E CONDENSADO'\n",
    "                                               ]\n",
    "                     }\n",
    "    for key, name in wellQualityMap.items():\n",
    "        if row['DMPO_NM_RCLS_POCO'] in name:\n",
    "            well_quality = key\n",
    "    return well_quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_well_instance(row, generate_synonyms = False):\n",
    "    if generate_synonyms:\n",
    "        wells = _well_names(row)\n",
    "    else:\n",
    "        wells = []\n",
    "        wells.append(row['DMPO_SG_PRFX_POCO'])\n",
    "        if row['DMPO_NM_CMPT_POCO'] != '':\n",
    "            wells.append(row['DMPO_NM_CMPT_POCO'])\n",
    "        if row['DMPO_SG_PRFX_POCO_ANP'] != '':\n",
    "            wells.append(row['DMPO_SG_PRFX_POCO_ANP'])\n",
    "        wells = set(wells)   \n",
    "        \n",
    "    new_well = _well_type(row)\n",
    "    #well_quality = _well_quality(row)\n",
    "    for well in wells:\n",
    "        new_well.label.append(well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('resources/poco/wellData.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wells = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in df_wells.iterrows():\n",
    "    _create_well_instance(row)\n",
    "    print(i)\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.save(file=\"OntoGeoLogicaInstancias.owl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Insert Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_zeros(x):\n",
    "    if isinstance(x, str):\n",
    "        return(0)\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "def treat_tables(df_poco, df_crono, df_unilito, df_lito):\n",
    "    #NO EXPLORA ESTÃO VINDO COM CARACTERE ADICIONAL VAZIO\n",
    "    df_poco.dropna(subset=['Sigla'], inplace=True)  \n",
    "    df_poco['Sigla'] = df_poco['Sigla'].apply(lambda x: x[1:])\n",
    "    \n",
    "    df_unilito['Unidade'] = df_unilito['Unidade'].apply(lambda x: x[1:])\n",
    "    df_unilito['Tipo Unidade'] = df_unilito['Tipo Unidade'].apply(lambda x: x[1:])\n",
    "    \n",
    "    df_crono['Unidade'] = df_crono['Unidade'].apply(lambda x: x[1:])\n",
    "    df_lito['Litologia'] = df_lito['Litologia'].apply(lambda x: x[1:])\n",
    "    \n",
    "    df_unilito['Topo'] = df_unilito['Topo'].apply(lambda x: fill_zeros(x))\n",
    "    df_unilito['Base'] = df_unilito['Base'].apply(lambda x: fill_zeros(x))\n",
    "    df_crono['Topo'] = df_crono['Topo'].apply(lambda x: fill_zeros(x))\n",
    "    df_crono['Base'] = df_crono['Base'].apply(lambda x: fill_zeros(x))\n",
    "    df_lito['Topo'] = df_lito['Topo'].apply(lambda x: fill_zeros(x))\n",
    "    df_lito['Base'] = df_lito['Base'].apply(lambda x: fill_zeros(x))\n",
    "    \n",
    "    df_litoestratigrafia = pd.merge(df_poco, df_unilito, how='outer')\n",
    "    df_litoestratigrafia['Bacia'] = df_litoestratigrafia['Bacia'].apply(lambda x: x[1:])\n",
    "    \n",
    "    return(df_litoestratigrafia, df_crono, df_lito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#ESSA PARTE DAS RELACOES SERA EXECUTADA POSTERIORMENTE\n",
    "    if well_quality != -1:\n",
    "        quality_label = str(well_quality).split('.')[1]\n",
    "        new_quality = well_quality(quality_label+'_'+str(row['DMPO_CD_POCO']).zfill(6))\n",
    "        new_quality.label.append(well_quality.label[0])\n",
    "        new_well.has_quality.append(new_quality)\n",
    "    \n",
    "    for bacia in onto.search(iri = \"*BASE_CD_BACIA_*\"):\n",
    "        if row['DMPO_NM_BACI'] in bacia.label:\n",
    "            new_well.located_in.append(bacia)\n",
    "    \n",
    "    for campo in onto.search(iri = \"*CAMP_CD_CAMPO_*\"):\n",
    "        if row['DMPO_NM_CAMP'] in campo.label:\n",
    "            new_well.located_in.append(campo)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_well_relations(df, onto, df_litoestratigrafia, df_crono, df_lito,\n",
    "                           bacia_mapper, crono_mapper, lito_mapper):\n",
    "    poco_problema=[]\n",
    "    unidade_lito_problema=[]\n",
    "    litologia_problema=[]\n",
    "    for i in list(df_litoestratigrafia.dropna(subset=['Unidade']).index):\n",
    "        print(str(i)+'/'+str(len(df_litoestratigrafia)))\n",
    "        #Procura a Bacia onde se localiza a Unidade Litoestratigráfica\n",
    "        bacia  = [k for k, v in bacia_mapper.items() if df_litoestratigrafia.loc[i]['Bacia'] in v]\n",
    "        if len(bacia)==0:\n",
    "            print('Bacia não encontrada:', df_litoestratigrafia.loc[i]['Bacia'])\n",
    "        else:\n",
    "            ind_bacia = onto.search(iri = '*BASE_CD_BACIA_'+bacia[0].zfill(3))\n",
    "        if df_litoestratigrafia.loc[i]['Sigla'] not in list(df['DMPO_NM_CMPT_POCO']):\n",
    "            #Verifica se o poço atravessado pela unidade lito consta da lista de poços que popula a ontologia\n",
    "            poco_problema.append(df_litoestratigrafia.loc[i]['Sigla'])\n",
    "        else:\n",
    "            key_poco = str(list(df[df['DMPO_NM_CMPT_POCO']==df_litoestratigrafia.loc[i]['Sigla']]['DMPO_CD_POCO'])[0]).zfill(6)\n",
    "            ind_poco = [f for f in onto.search(iri =\"*POCO_CD_POCO*\") if key_poco in str(f)]\n",
    "            if len(ind_poco) == 1:\n",
    "                topo_lito = float(df_litoestratigrafia.loc[i]['Topo'])\n",
    "                base_lito = float(df_litoestratigrafia.loc[i]['Base'])\n",
    "                tipo_unidade = unicodedata.normalize('NFD',df_litoestratigrafia.loc[i]['Tipo Unidade'].lower())\n",
    "                tipo_unidade = tipo_unidade.encode('ascii', 'ignore').decode('ascii', 'ignore')\n",
    "                #Verifica se a Unidade Litoestratigráfica consta da lista de unidades que popula a ontologia\n",
    "                if len(onto.search(iri = \"*\"+tipo_unidade+\"*\"))==0:\n",
    "                    #Verifica se o a unidade lito consta da lista de unidades que popula a ontologia\n",
    "                    unidade_lito_problema.append(df_litoestratigrafia.loc[i]['Unidade'])\n",
    "                for unilito in onto.search(iri = \"*\"+tipo_unidade+\"*\"):\n",
    "                    labels = unilito.label\n",
    "                    labels = [l.lower() for l in labels]\n",
    "                    labels = [unicodedata.normalize('NFD', l).encode('ascii', 'ignore').decode('ascii', 'ignore') \n",
    "                              for l in labels]\n",
    "                    if df_litoestratigrafia.loc[i]['Unidade'].lower() in labels:\n",
    "                        ind_poco[0].atravessa.append(unilito)\n",
    "                        for bacia in ind_bacia:\n",
    "                            unilito.located_in.append(bacia)\n",
    "                        #PREENCHIMENTO DAS RELAÇÕES DE UNIDADES CRONOESTRATIGRÁFICAS COM A LITOESTRATIGRÁFICAS (tem_idade)\n",
    "                        df_cronoestratigrafia = df_crono[df_crono['Poço']==df_litoestratigrafia['Poço'][i]]\n",
    "                        for j in list(df_cronoestratigrafia.index):\n",
    "                            topo_crono = float(df_cronoestratigrafia.loc[j]['Topo'])\n",
    "                            base_crono = float(df_cronoestratigrafia.loc[j]['Base'])\n",
    "                            #idade = unicodedata.normalize('NFD',df_cronoestratigrafia.loc[i]['Unidade'].lower())\n",
    "                            #idade = idade.encode('ascii', 'ignore').decode('ascii', 'ignore')\n",
    "                            if (topo_lito!=0) & (base_lito!=0) & (topo_crono!=0):\n",
    "                                if (((topo_lito >= topo_crono)&(topo_lito <= base_crono))|\n",
    "                                    ((base_lito >= topo_crono)&(base_lito <= base_crono))):\n",
    "                                    crono = [k for k, v in crono_mapper.items() if \n",
    "                                             df_cronoestratigrafia.loc[j]['Unidade'] in v][0].split('.')[1]\n",
    "                                    crono_quality = onto.search(iri = '*'+crono)[0]\n",
    "                                    geochronology = crono.replace(\"_quality\", \"\")\n",
    "                                    crono_geochronology = onto.search(iri = '*'+geochronology)[0]\n",
    "                                    crono_unilito = str(crono_quality).split('.')[1]+'_'+str(unilito).split('.')[1].zfill(4)\n",
    "                                    if len(onto.search(iri = '*'+crono_unilito))==0:\n",
    "                                        new_crono_quality = crono_quality(crono_unilito)\n",
    "                                        unilito.has_age.append(new_crono_quality)\n",
    "                                        new_crono_quality.label.append(crono_quality.label[0])\n",
    "                                        new_crono_quality.participates_in.append(crono_geochronology)\n",
    "                                elif ((topo_lito < topo_crono)&(base_lito > base_crono)):\n",
    "                                    crono = [k for k, v in crono_mapper.items() if \n",
    "                                             df_cronoestratigrafia.loc[j]['Unidade'] in v][0].split('.')[1]\n",
    "                                    crono_quality = onto.search(iri = '*'+crono)[0]\n",
    "                                    geochronology = crono.replace(\"_quality\", \"\")\n",
    "                                    crono_geochronology = onto.search(iri = '*'+geochronology)[0]\n",
    "                                    crono_unilito = str(crono_quality).split('.')[1]+'_'+str(unilito).split('.')[1].zfill(4)\n",
    "                                    if len(onto.search(iri = '*'+crono_unilito))==0:\n",
    "                                        new_crono_quality = crono_quality(crono_unilito)\n",
    "                                        unilito.has_age.append(new_crono_quality)\n",
    "                                        new_crono_quality.label.append(crono_quality.label[0])\n",
    "                                        new_crono_quality.participates_in.append(crono_geochronology)\n",
    "                        #POVOAMENTO DAS LITOLOGIAS QUE COMPÕEM LITOESTRATIGRAFIAS\n",
    "                        df_litologia = df_lito[df_lito['Poço']==df_litoestratigrafia['Poço'][i]]\n",
    "                        lito = []\n",
    "                        for k in list(df_litologia.index):\n",
    "                            topo_rocha = float(df_litologia.loc[k]['Topo'])\n",
    "                            base_rocha = float(df_litologia.loc[k]['Base'])\n",
    "                            litologia = unicodedata.normalize('NFD',df_litologia.loc[k]['Litologia'].lower())\n",
    "                            if (topo_lito!=0) & (base_lito!=0) & (topo_rocha!=0):\n",
    "                                if ((topo_rocha >= topo_lito)&(base_rocha <= base_lito)):\n",
    "                                    if litologia in [l for sublist in list(lito_mapper.values()) for l in sublist]:\n",
    "                                        lito.append([k for k, v in lito_mapper.items() if \n",
    "                                                     litologia in v][0].split('.')[1])\n",
    "                        for l in set(lito):\n",
    "                            if len(onto.search(iri = '*'+l+'*'))>0:\n",
    "                                name_ind = (l+'_'+str(unilito).split('.')[1]).zfill(4)\n",
    "                                if len(onto.search(iri = '*'+name_ind))==0:\n",
    "                                    #print(name_ind)\n",
    "                                    new_ind = onto.search(iri = '*'+l)[0](name_ind)\n",
    "                                    unilito.constituted_by.append(new_ind)\n",
    "                                    labels=onto.search(iri = '*'+l)[0].label\n",
    "                                    for label in labels:\n",
    "                                        new_ind.label.append(label)\n",
    "                                #else:\n",
    "                                    #print('rocha existente')\n",
    "                            else:\n",
    "                                litologia_problema.append(l)\n",
    "                        break\n",
    "            else:\n",
    "                print('mais de um poço')\n",
    "    return(poco_problema, unidade_lito_problema, litologia_problema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/bacia/bacias.json', 'r') as f:\n",
    "    bacia_mapper = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bacia_mapper['281'].append('CAMPOS (MAR)')\n",
    "bacia_mapper['260'].append('MUCURI (TERRA)')\n",
    "bacia_mapper['116'].append('SERGIPE (TERRA)')\n",
    "bacia_mapper['116'].append('SERGIPE (MAR)')\n",
    "bacia_mapper['90'].append('PARNAIBA')\n",
    "bacia_mapper['20'].append('SOLIMOES')\n",
    "bacia_mapper['60'].append('BRAGANCA-VIZEU')\n",
    "bacia_mapper['100'].append('POTIGUAR (TERRA)')\n",
    "bacia_mapper['240'].append('RECONCAVO (TERRA)')\n",
    "bacia_mapper['240'].append('RECONCAVO (MAR)')\n",
    "bacia_mapper['270'].append('ESPIRITO SANTO (TERRA)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/cronoestratigrafia/unidades_crono.json', 'r') as f:\n",
    "    crono_mapper = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for age in crono_mapper:\n",
    "    for label in crono_mapper[age]:\n",
    "        norm_label = unicodedata.normalize('NFD',label).encode('ascii', 'ignore').decode('ascii', 'ignore')\n",
    "        if norm_label not in crono_mapper[age]:\n",
    "            crono_mapper[age].append(norm_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crono_mapper['onto.Ypresian_quality'].append('Eoceno Inferior')\n",
    "crono_mapper['onto.Eoriodaserra_Subage_quality'].append('Rio da Serra Inferior')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crono_mapper['onto.Upper_Frasnian_Subage_quality'] = ['Neofrasniano',\n",
    "                                                      'Frasniano Superior',\n",
    "                                                      'Subandar Frasniano Superior',\n",
    "                                                      'Subidade Neofrasniana']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('resources/litologia/litologia.json', 'r') as f:\n",
    "    lito_mapper = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onto_path.append(\"/ner_geologica/GeoCoreOntology.owl\")\n",
    "#onto = get_ontology(\"file://ner_geologica/ner_geologica.owl\")\n",
    "onto = get_ontology(\"file://OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chave  = os.getenv('BG40')\n",
    "senha  = getpass('Senha: ')\n",
    "\n",
    "os.environ['HTTP_PROXY']  = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['HTTPS_PROXY'] = f'http://{chave}:{senha}@inet-sys.petrobras.com.br:804'\n",
    "os.environ['NO_PROXY']    = '127.0.0.1, localhost, petrobras.com.br, petrobras.biz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "onto.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(onto.search(iri = '*sandstone*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#JACUIPE, 'PANTANAL',\n",
    "bacias=['ACRE', 'AMAZONAS', 'BARREIRINHAS', 'BRAGANCA-VIZEU', 'CAMAMU-ALMADA', 'CEARA',\n",
    "        'CUMURUXATIBA', 'FOZ_DO_AMAZONAS', 'JATOBA', 'JEQUITINHONHA', 'MARAJO', 'MUCURI_MAR', 'MUCURI_TERRA',\n",
    "        'PARA-MARANHAO','PARANA', 'PARECIS-ALTO_XINGU', 'PARNAIBA', 'PELOTAS', 'PERNAMBUCO-PARAIBA', 'RIO_DO_PEIXE',\n",
    "        'SAO_FRANCISCO', 'SAO_LUIS', 'SOLIMOES', 'TACUTU', 'TUCANO_CENTRAL', 'TUCANO_NORTE', 'TUCANO_SUL',\n",
    "        'SANTOS','CAMPOS', 'POTIGUAR', 'ESPIRITO_SANTO', 'SERGIPE-ALAGOAS', 'RECONCAVO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#bacias = []\n",
    "poco_problema=[]\n",
    "unidade_lito_problema=[]\n",
    "litologia_problema=[]\n",
    "\n",
    "for b in bacias:\n",
    "    clear_output()\n",
    "    print(b)\n",
    "    df_poco = pd.read_excel('resources/explora/'+b+'_Informações_Gerais.xlsx')\n",
    "    df_crono = pd.read_excel('resources/explora/'+b+'_Cronoestratigrafia.xlsx')\n",
    "    df_unilito = pd.read_excel('resources/explora/'+b+'_Litoestratigrafia.xlsx')\n",
    "    df_lito = pd.read_excel('resources/explora/'+b+'_Litologia_Interpretada.xlsx')\n",
    "    df_litoestratigrafia, df_crono, df_lito = treat_tables(df_poco, df_crono, df_unilito, df_lito)\n",
    "    p, u, l = _create_well_relations(df, onto, df_litoestratigrafia, df_crono, df_lito,\n",
    "                                     bacia_mapper, crono_mapper, lito_mapper)\n",
    "    \n",
    "    onto.save(file=\"OntoGeoLogicaPovoadaInstanciasRelacoes.owl\")\n",
    "    poco_problema.append(p)\n",
    "    unidade_lito_problema.append(u)\n",
    "    litologia_problema.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.search(iri = '*Jiquia_Age_quality*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with onto:\n",
    "    sync_reasoner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.Paleogene.has_participant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.formacao_088.has_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.formacao_088.crossed_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.POCO_CD_POCO_022601.atravessa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.formacao_088.constituted_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.formacao_088.located_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.BASE_CD_BACIA_010.location_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
