{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise do AQE Python\n",
    "\n",
    "Nesta análise, vamos avaliar a performance de tempo de resposta do AQE Python, assim como do ranking de documentos retornados pelo elasticsearch através da consulta expandida pelo AQE. Vamos utilizar as queries definidas na [base REGIS](https://github.com/Petroles/regis-collection/) para avaliação do AQE Python.\n",
    "\n",
    "Para esta análise é necessário ter acesso ao AQE Python rodando, bem como ao elasticsearch, apontando as variáveis necessárias no `.env`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from utils.utils import create_metrics, create_ranking_dataset, \\\n",
    "    retrieve_from_elasticsearch\n",
    "\n",
    "requests.packages.urllib3.util.connection.HAS_IPV6 = False\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando consultas e calculando tempo de resposta\n",
    "\n",
    "Agora vamos realizar as consultas das queries do REGIS para o AQE Python, calculando o tempo de resposta. Para cada query, vamos fazer o request 30 vezes, para identificar também a variação do tempo de resposta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/regis_queries.json\", \"r\") as json_file:\n",
    "    regis_queries = json.loads(json_file.read())\n",
    "\n",
    "certificate_path = \"../PetrobrasCARootCorporativa.crt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_requests = 30\n",
    "max_expanded_terms = 5\n",
    "aqe_base_url = os.getenv(\"AQE_URL\")\n",
    "\n",
    "df_data = list()\n",
    "for i in range(number_of_requests):\n",
    "    for query in regis_queries:\n",
    "        query_title = query.get(\"title\")\n",
    "        query_id = query.get(\"query_id\")\n",
    "        url_query = f\"{aqe_base_url}?query={query_title}&max_expanded_terms={max_expanded_terms}\"\n",
    "        start = time.time()\n",
    "        response = requests.get(\n",
    "            url_query,\n",
    "            verify=certificate_path\n",
    "        )\n",
    "        end = time.time()\n",
    "        response_time = (end - start) * 1000\n",
    "\n",
    "        df_data.append(\n",
    "            query | {\n",
    "                \"response\": response.text,\n",
    "                \"response_time_ms\": response_time,\n",
    "                \"num_original_terms\": query_title.count(\" \") + 1,\n",
    "                \"num_expanded_terms\": len(re.findall(\"\\^[0-1].[0-9]{3}\", response.text)),\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_df = pd.DataFrame(df_data)\n",
    "response_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisando tempo de resposta\n",
    "\n",
    "Primeiramente vamos analisar o tempo de resposta das queries de uma maneira geral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    response_df, x=\"response_time_ms\", nbins=15,\n",
    "    title=\"Tempo de resposta do AQE Python\",\n",
    "    labels={\n",
    "        \"response_time_ms\": \"Tempo de resposta (ms)\",\n",
    "    }\n",
    ").update_layout(\n",
    "    yaxis_title_text=\"Contagem de requisições\",\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a distribuição dos tempos de resposta tem uma maior frequência entre os 100 e 150 ms, com uma longa cauda a direita, que chega próximo dos 500 ms.\n",
    "\n",
    "Vejamos agora o tempo de resposta para cada uma das queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.box(\n",
    "    response_df, x=\"query_id\", y=\"response_time_ms\",\n",
    "    title=\"Tempo de resposta das queries\",\n",
    "    labels={\n",
    "        \"query_id\": \"Query ID\",\n",
    "        \"response_time_ms\": \"Tempo de resposta (ms)\",\n",
    "    }\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que o tempo de resposta tem uma variação considerável, em alguns casos variando próximo dos 200 ms.\n",
    "\n",
    "Vejamos agora as medianas de cada query para ver a tendência central dos tempos de resposta de cada query, atenuando as variações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_viz = response_df.groupby(\n",
    "    \"query_id\"\n",
    ").agg(\n",
    "    {\"response_time_ms\": \"median\"}\n",
    ").reset_index()\n",
    "\n",
    "fig = px.bar(\n",
    "    data_viz, x=\"query_id\", y=\"response_time_ms\",\n",
    "    title=\"Tempo mediano de resposta das queries\",\n",
    "    labels={\n",
    "        \"query_id\": \"Query ID\",\n",
    "        \"response_time_ms\": \"Mediana do tempo de resposta (ms)\",\n",
    "    }\n",
    ").add_hline(\n",
    "    y=response_df.response_time_ms.median(),\n",
    "    annotation_text=f\"{response_df.response_time_ms.median():.0f} ms\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que a mediana do tempo de resposta fica entre 150 e 200 ms e que mediana da Q14, Q26 e Q34 possui os maiores valores, acima dos 400 ms, enquanto a Q6 possui o menor tempo de resposta, próximo dos 45 ms."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando consultas no Elasticsearch\n",
    "\n",
    "Agora vamos realizar as consultas ao elastic search e criar o dataset de validação, o qual possui informações do ground truth da base de dados REGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"elasticsearch\": {\n",
    "        \"url\": os.getenv(\"ELASTIC_SEARCH_URL\"),\n",
    "        \"index\": os.getenv(\"ELASTIC_SEARCH_INDEX\"),\n",
    "        \"username\": os.getenv(\"ELASTIC_SEARCH_USERNAME\"),\n",
    "        \"password\": os.getenv(\"ELASTIC_SEARCH_PASSWORD\"),\n",
    "        \"certificate\": certificate_path\n",
    "    }\n",
    "}\n",
    "\n",
    "queries = response_df.filter(\n",
    "    items=[\"query_id\", \"response\"]\n",
    ").drop_duplicates(\n",
    ").itertuples(\n",
    "    index=False, name=None\n",
    ")\n",
    "queries = list(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_result_df = retrieve_from_elasticsearch(queries, cfg, 24)\n",
    "ranking_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\"../data/regis_ground_truth.csv\")\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_dataset = create_ranking_dataset(ranking_result_df, ground_truth)\n",
    "ranking_dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das consultas no Elasticsearch\n",
    "\n",
    "Agora vamos criar as métricas para cada base de dados e fator e visualizar os resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = create_metrics(ranking_dataset, groupby_columns=[\"query_id\"])\n",
    "metrics_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando métricas\n",
    "\n",
    "Vamos agora avaliar as métricas de ranking utilizando o NDCG (Normalized Discounted Cumulative Gain) como métrica de desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(\n",
    "    metrics_df, x=\"query_id\", y=\"ndcg\",\n",
    "    title=\"NDCG das queries\",\n",
    "    labels={\n",
    "        \"query_id\": \"Query ID\",\n",
    "        \"ndcg\": \"NDCG (Normalized Discounted Cumulative Gain)\",\n",
    "    }\n",
    ").add_hline(\n",
    "    y=metrics_df.ndcg.mean(),\n",
    "    annotation_text=f\"NDCG médio {metrics_df.ndcg.mean():.4f}\"\n",
    ").update_layout(xaxis={\"categoryorder\":\"total descending\"})\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que O NDCG médio foi de 81,31% e que apenas três das 34 queries (8,8%) obtiveram um NDCG abaixo dos 60%."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Pudemos ver nesta análise que o tempo de resposta das queries para o AQE Python varia entre 0 e 500 ms, sendo o valor mais frequente fica entre 100 e 150 ms.\n",
    "Vimos também que a métricas de ranking atingida com o AQE Python foi de 81,31%, utilizando o NDCG@24."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "petrobras",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
