{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise do impacto das expansões do AQE no ranking\n",
    "\n",
    "Nesta análise vamos identificar o impacto das expansões realizadas pelo AQE nas métricas de ranking. O objetivo é identificar se utilizar mais termos na expansão pode implicar na diminuição das métricas de ranking, tendo em vista que mais documentos são recuperados. Para medir a performance do ranking vamos utilizar as queries da [base REGIS](https://github.com/Petroles/regis-collection). Para remover qualquer interferência de diferentes fatores de boosting, vamos utilizar um fator de boosting padrão de 0,1 para todos os termos expandidos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import json\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "from utils.utils import get_expanded_queries, make_elasticsearch_new_aqe_queries,\\\n",
    "    create_new_expanded_queries, create_new_aqe_validation_dataset, create_new_aqe_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando as configurações e bases dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../conf/config.yaml\", \"r\") as yamlfile:\n",
    "    cfg = yaml.safe_load(yamlfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../dados/regis/regis_queries.json\", 'r') as regis_file:\n",
    "    regis_queries = json.load(regis_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regis_queries = get_expanded_queries(regis_queries)\n",
    "regis_queries[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando queries com diferentes quantidades de expansões\n",
    "\n",
    "Aqui vamos os conjuntos de termos expandidos para cada termo original da query, de forma que para cada termo original utilize parte de seus termos derivados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_expanded_queries = list()\n",
    "for query in regis_queries:\n",
    "    new_expanded_queries = create_new_expanded_queries(query[\"expanded_query\"])\n",
    "    for num_boosts, new_expanded_query in new_expanded_queries:\n",
    "        q = query.copy()\n",
    "        q[\"expanded_query\"] = new_expanded_query\n",
    "        q[\"num_boosts\"] = num_boosts\n",
    "        all_expanded_queries.append(q)\n",
    "all_expanded_queries[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realizando consultas no Elasticsearch\n",
    "\n",
    "Em posse das queries que utilizam diferentes quantidades de termos com boosting do elastic search vamos criar o dataset de validação, o qual possui informações do ground truth da base de dados REGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_result_df = make_elasticsearch_new_aqe_queries(\n",
    "    all_expanded_queries,\n",
    "    cfg,\n",
    "    num_docs=24\n",
    ")\n",
    "ranking_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = pd.read_csv(\n",
    "    \"../../dados/regis/regis_ground_truth.csv\"\n",
    ").rename(\n",
    "    columns={\"relevance\": \"relevance_ground_truth\"}\n",
    ")\n",
    "ground_truth.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = create_new_aqe_validation_dataset(ranking_result_df, ground_truth)\n",
    "validation_dataset.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise das consultas no Elasticsearch\n",
    "\n",
    "Agora vamos criar as métricas para cada base de dados e quantidade de termos derivados e visualizar os resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = create_new_aqe_metrics(validation_dataset)\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv(\"../data/aqe_expansions_metrics.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando métricas\n",
    "\n",
    "Vamos agora avaliar as métricas. Vamos utilizar as seguintes métricas:\n",
    "\n",
    "* ndcg - Normalized Discounted Cumulative Gain\n",
    "* map - Mean Average Precision\n",
    "* eval_prop - Proporção de documentos avaliados\n",
    "\n",
    "Vejamos a performance das queries ao longo das diferentes quantidades de boost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(\n",
    "    metrics_df,\n",
    "    x=\"num_boosts\",\n",
    "    y=\"ndcg\",\n",
    "    color=\"query_id\",\n",
    "    markers=True,\n",
    "    title=\"Performances das queries com diferentes quantidades de boosts\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como a visualização ficou poluída, vamos verificar para cada query qual a quantidade de boosts que obteve melhor NDCG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_viz = metrics_df.groupby(\n",
    "    \"query_id\"\n",
    ").agg({\n",
    "    \"ndcg\": \"max\"\n",
    "}).reset_index(\n",
    ").merge(\n",
    "    metrics_df, how=\"left\", on=[\"query_id\", \"ndcg\"]\n",
    ").sort_values(\n",
    "    [\"query_id\", \"num_boosts\"]\n",
    ").drop_duplicates(\n",
    "    subset=\"query_id\", keep=\"first\"\n",
    ")\n",
    "data_viz.head()\n",
    "\n",
    "fig = px.scatter(\n",
    "    data_viz,\n",
    "    x=\"num_boosts\",\n",
    "    y=\"ndcg\",\n",
    "    labels={\n",
    "        \"num_boosts\": \"Número de termos\",\n",
    "        \"ndcg\": \"NDCG\",\n",
    "    },\n",
    "    hover_data=[\"query_id\", \"num_boosts\", \"ndcg\"],\n",
    "    title=\"Melhor número de termos por query\",\n",
    "    marginal_x=\"histogram\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É possível ver que a maior parte dos pontos está abaixo de 10 termos de boosting, apesar de quase a totalidade das queries terem mais que 10 termos. Além disso, as queries que obtiveram maior NDCG estão abaixo de 10 termos.\n",
    "\n",
    "Vejamos qual corte de quantidade de boosting traz os melhores resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_boosts_prod = pd.DataFrame(\n",
    "    product(metrics_df[\"query_id\"].unique(), metrics_df[\"num_boosts\"].unique()),\n",
    "    columns=[\"query_id\", \"num_boosts\"]\n",
    ")\n",
    "\n",
    "data_viz = queries_boosts_prod.merge(\n",
    "    metrics_df, on=[\"query_id\", \"num_boosts\"], how=\"left\"\n",
    ").fillna(\n",
    "    method=\"ffill\"\n",
    ").groupby(\n",
    "    \"num_boosts\"\n",
    ").agg(\n",
    "    mean_ndcg = (\"ndcg\", \"mean\")\n",
    ").reset_index()\n",
    "\n",
    "fig = px.line(\n",
    "    data_viz,\n",
    "    x=\"num_boosts\",\n",
    "    y=\"mean_ndcg\",\n",
    "    labels={\n",
    "        \"num_boosts\": \"Número de termos\",\n",
    "        \"mean_ndcg\": \"NDCG médio\",\n",
    "    },\n",
    "    markers=True,\n",
    "    title=\"NDCG médio para cada número de termos\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que existe uma tendência decrescente no NDCG médio ao aumentar a quantidade de termos do AQE. Utilizar uma poda abaixo de 10 termos é algo razoável."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusão\n",
    "\n",
    "Pudemos ver que utilizar o AQE traz um ganho maior quando apenas uma parte dos termos são utilizados.\n",
    "O AQE traz entre 1 e 49 termos derivados dos termos originais e foi possível ver que utilizar menos de 10 termos traz um melhor resultado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
